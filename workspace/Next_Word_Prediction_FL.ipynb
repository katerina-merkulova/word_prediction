{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "liquid-jacket",
   "metadata": {},
   "source": [
    "# Federated Next Word Prediction with Director example\n",
    "## Using low-level Python API"
   ]
  },
  {
   "cell_type": "raw",
   "id": "db949008",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "source": [
    "# Install dependencies if not already installed\n",
    "!pip uninstall tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16986f22",
   "metadata": {},
   "source": [
    "# Connect to the Federation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4485ac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a federation\n",
    "from openfl.interface.interactive_api.federation import Federation\n",
    "\n",
    "# please use the same identificator that was used in signed certificate\n",
    "cliend_id = 'frontend'\n",
    "\n",
    "# 1) Run with API layer - Director mTLS \n",
    "# If the user wants to enable mTLS their must provide CA root chain, and signed key pair to the federation interface\n",
    "# cert_chain = 'cert/root_ca.crt'\n",
    "# API_certificate = 'cert/frontend.crt'\n",
    "# API_private_key = 'cert/frontend.key'\n",
    "\n",
    "# federation = Federation(client_id='frontend', director_node_fqdn='localhost', director_port='50051', disable_tls=False,\n",
    "#                        cert_chain=cert_chain, api_cert=API_certificate, api_private_key=API_private_key)\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# 2) Run with TLS disabled (trusted environment)\n",
    "# Federation can also determine local fqdn automatically\n",
    "federation = Federation(client_id='frontend', director_node_fqdn='localhost', director_port='50051', tls=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e35802d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'env_one': {'shard_info': node_info {\n",
       "    name: \"env_one\"\n",
       "  }\n",
       "  shard_description: \"Market dataset, shard number 1 out of 2\"\n",
       "  n_samples: 6468\n",
       "  sample_shape: \"64\"\n",
       "  sample_shape: \"128\"\n",
       "  sample_shape: \"3\"\n",
       "  target_shape: \"1501\",\n",
       "  'is_online': True,\n",
       "  'is_experiment_running': False,\n",
       "  'last_updated': '2021-08-16 21:04:28',\n",
       "  'current_time': '2021-08-16 21:04:45',\n",
       "  'valid_duration': seconds: 60},\n",
       " 'env_two': {'shard_info': node_info {\n",
       "    name: \"env_two\"\n",
       "  }\n",
       "  shard_description: \"Market dataset, shard number 2 out of 2\"\n",
       "  n_samples: 6468\n",
       "  sample_shape: \"64\"\n",
       "  sample_shape: \"128\"\n",
       "  sample_shape: \"3\"\n",
       "  target_shape: \"1501\",\n",
       "  'is_online': True,\n",
       "  'is_experiment_running': False,\n",
       "  'last_updated': '2021-08-16 21:04:31',\n",
       "  'current_time': '2021-08-16 21:04:45',\n",
       "  'valid_duration': seconds: 60}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shard_registry = federation.get_shard_registry()\n",
    "shard_registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67ae50de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1501']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "federation.target_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b42efc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, request a dummy_shard_desc that holds information about the federated dataset \n",
    "dummy_shard_desc = federation.get_dummy_shard_descriptor(size=10)\n",
    "sample, target = dummy_shard_desc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-tyler",
   "metadata": {},
   "source": [
    "## Creating a FL experiment using Interactive API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "rubber-address",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfl.interface.interactive_api.experiment import TaskInterface, DataInterface, ModelInterface, FLExperiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-public",
   "metadata": {},
   "source": [
    "### Register dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64f37dcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now you can implement you data loaders using dummy_shard_desc\n",
    "class NextWordSD(DataInterface, Dataset):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    @property\n",
    "    def shard_descriptor(self):\n",
    "        return self._shard_descriptor\n",
    "\n",
    "    @shard_descriptor.setter\n",
    "    def shard_descriptor(self, shard_descriptor):\n",
    "        \"\"\"\n",
    "        Describe per-collaborator procedures or sharding.\n",
    "\n",
    "        This method will be called during a collaborator initialization.\n",
    "        Local shard_descriptor will be set by Envoy.\n",
    "        \"\"\"\n",
    "        self._shard_descriptor = shard_descriptor\n",
    "\n",
    "    def __getitem__(self, index): # todo\n",
    "        img, pid = self.shard_descriptor[index]\n",
    "        img = self.img_trans(img).numpy()\n",
    "        return img, pid\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.shard_descriptor)\n",
    "\n",
    "    def get_train_loader(self, **kwargs): # todo\n",
    "        \"\"\"\n",
    "        Output of this method will be provided to tasks with optimizer in contract\n",
    "        \"\"\"\n",
    "        if self.kwargs['train_bs']:\n",
    "            batch_size = self.kwargs['train_bs']\n",
    "        else:\n",
    "            batch_size = 64\n",
    "\n",
    "        return DataLoader(\n",
    "            ImageDataset(self.shard_descriptor.train, transform=self.transform_train),\n",
    "            sampler=RandomIdentitySampler(self.shard_descriptor.train, num_instances=4),\n",
    "            batch_size=batch_size, num_workers=4, pin_memory=True, drop_last=True\n",
    "        )\n",
    "\n",
    "    def get_valid_loader(self, **kwargs): # todo\n",
    "        \"\"\"\n",
    "        Output of this method will be provided to tasks without optimizer in contract\n",
    "        \"\"\"\n",
    "        if self.kwargs['valid_bs']:\n",
    "            batch_size = self.kwargs['valid_bs']\n",
    "        else:\n",
    "            batch_size = 512\n",
    "\n",
    "        return (\n",
    "            DataLoader(ImageDataset(self.shard_descriptor.query, transform=self.transform_test),\n",
    "                       batch_size=batch_size, num_workers=4, pin_memory=True,\n",
    "                       drop_last=False, shuffle=False),\n",
    "            DataLoader(ImageDataset(self.shard_descriptor.gallery, transform=self.transform_test),\n",
    "                       batch_size=batch_size, num_workers=4, pin_memory=True,\n",
    "                       drop_last=False, shuffle=False)\n",
    "        )\n",
    "\n",
    "    def get_train_data_size(self): # todo\n",
    "        \"\"\"\n",
    "        Information for aggregation\n",
    "        \"\"\"\n",
    "        return self.shard_descriptor.num_train_pids\n",
    "\n",
    "    def get_valid_data_size(self): # todo\n",
    "        \"\"\"\n",
    "        Information for aggregation\n",
    "        \"\"\"\n",
    "        return self.shard_descriptor.num_gallery_pids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cb6c73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_dataset = NextWordSD(train_bs=64, valid_bs=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-distinction",
   "metadata": {},
   "source": [
    "### Describe a model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85855c9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "vocab_size = 2573\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 10, input_length=1))\n",
    "model.add(LSTM(1000, return_sequences=True))\n",
    "model.add(LSTM(1000))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420fa426",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model as tf_model\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "\n",
    "class Model(tf_model):\n",
    "    \"\"\" Model definition \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        vocab_size = 2573\n",
    "        self.emb = Embedding(vocab_size, 10, input_length=1)\n",
    "        self.lstm1 = LSTM(1000, return_sequences=True)\n",
    "        self.lstm2 = LSTM(1000)\n",
    "        self.d1 = Dense(1000, activation='relu')\n",
    "        self.d2 = Dense(vocab_size, activation='softmax')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.emb(x)\n",
    "        x = self.lstm1(x)\n",
    "        x = self.lstm2(x)\n",
    "        x = self.d1(x)\n",
    "        x = self.d2(x)\n",
    "        return x\n",
    "\n",
    "    def train_step(self, data):    # https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit\n",
    "        # Unpack the data. Its structure depends on your model and\n",
    "        # on what you pass to `fit()`.\n",
    "        x, y = data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x, training=True)  # Forward pass\n",
    "            # Compute the loss value\n",
    "            # (the loss function is configured in `compile()`)\n",
    "            loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
    "\n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        # Return a dict mapping metric names to current value\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-passion",
   "metadata": {},
   "source": [
    "#### Register model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "handled-teens",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "framework_adapter = 'openfl.plugins.frameworks_adapters.keras_adapter.FrameworkAdapterPlugin'\n",
    "MI = ModelInterface(model=model, optimizer=optimizer, framework_plugin=framework_adapter)\n",
    "# Save the initial model state\n",
    "initial_model = deepcopy(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-groove",
   "metadata": {},
   "source": [
    "### Define and register FL tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "increasing-builder",
   "metadata": {},
   "outputs": [],
   "source": [
    "TI = TaskInterface()\n",
    "\n",
    "from logging import getLogger\n",
    "\n",
    "logger = getLogger(__name__)\n",
    "\n",
    "# Task interface currently supports only standalone functions.\n",
    "@TI.register_fl_task(model='model', data_loader='train_loader',\n",
    "                     device='device', optimizer='optimizer')\n",
    "def train(model, train_loader, optimizer, device=''):\n",
    "    device = torch.device('cuda')\n",
    "    \n",
    "    criterion_cla = ArcFaceLoss(scale=16., margin=0.1)\n",
    "    criterion_pair = TripletLoss(margin=0.3, distance='cosine')\n",
    "\n",
    "    batch_cla_loss = AverageMeter()\n",
    "    batch_pair_loss = AverageMeter()\n",
    "    corrects = AverageMeter()\n",
    "    \n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    model.classifier.train()\n",
    "    model.classifier.to(device)\n",
    "    \n",
    "    logger.info('==> Start training')\n",
    "    train_loader = tqdm.tqdm(train_loader, desc='train')\n",
    "\n",
    "    for batch_idx, (imgs, pids, _) in enumerate(train_loader):\n",
    "        imgs, pids = torch.tensor(imgs).to(device), torch.tensor(pids).to(device)\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward\n",
    "        features = model(imgs)\n",
    "        outputs = model.classifier(features)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        # Compute loss\n",
    "        cla_loss = criterion_cla(outputs, pids)\n",
    "        pair_loss = criterion_pair(features, pids)\n",
    "        loss = cla_loss + pair_loss\n",
    "        # Backward + Optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # statistics\n",
    "        corrects.update(torch.sum(preds == pids.data).float()/pids.size(0), pids.size(0))\n",
    "        batch_cla_loss.update(cla_loss.item(), pids.size(0))\n",
    "        batch_pair_loss.update(pair_loss.item(), pids.size(0))\n",
    "\n",
    "    return {'ArcFaceLoss': batch_cla_loss.avg,\n",
    "            'TripletLoss': batch_pair_loss.avg,\n",
    "            'Accuracy': corrects.avg.cpu()}\n",
    "\n",
    "\n",
    "@TI.register_fl_task(model='model', data_loader='val_loader', device='device')\n",
    "def validate(model, val_loader, device):\n",
    "    queryloader, galleryloader = val_loader\n",
    "    device = torch.device('cuda')\n",
    "    \n",
    "    logger.info('==> Start validating')\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    # Extract features for query set\n",
    "    qf, q_pids, q_camids = extract_feature(model, queryloader)\n",
    "    logger.info(f'Extracted features for query set, obtained {qf.shape} matrix')\n",
    "    # Extract features for gallery set\n",
    "    gf, g_pids, g_camids = extract_feature(model, galleryloader)\n",
    "    logger.info(f'Extracted features for gallery set, obtained {gf.shape} matrix')\n",
    "    # Compute distance matrix between query and gallery\n",
    "    m, n = qf.size(0), gf.size(0)\n",
    "    distmat = torch.zeros((m,n))\n",
    "    # Cosine similarity\n",
    "    qf = nn.functional.normalize(qf, p=2, dim=1)\n",
    "    gf = nn.functional.normalize(gf, p=2, dim=1)\n",
    "    for i in range(m):\n",
    "        distmat[i] = - torch.mm(qf[i:i+1], gf.t())\n",
    "    distmat = distmat.numpy()\n",
    "\n",
    "    cmc, mAP = evaluate(distmat, q_pids, g_pids, q_camids, g_camids)\n",
    "    return {'top1': cmc[0], 'top5': cmc[4], 'top10': cmc[9], 'mAP': mAP}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "derived-bride",
   "metadata": {},
   "source": [
    "## Time to start a federated learning experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "mature-renewal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an experimnet in federation\n",
    "experiment_name = 'market_test_experiment'\n",
    "fl_experiment = FLExperiment(federation=federation, experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "lightweight-causing",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[21:05:50] </span><span style=\"color: #000080\">INFO</span>     Building <span style=\"color: #800000\">🡆</span> Object <span style=\"color: #800000\">CloudpickleSerializer</span> from <span style=\"color: #800000\">openfl.plugins.interface_serializer.cloudpickle_serializer</span> Module.                  <a href=\"file:///home/merkulov/openfl/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:172</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f2424c96950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     Settings <span style=\"color: #800000\">🡆</span> <span style=\"font-weight: bold\">{}</span>                                                                                                                    <a href=\"file:///home/merkulov/openfl/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:174</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f249eefaad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     Override <span style=\"color: #800000\">🡆</span> <span style=\"font-weight: bold\">{}</span>                                                                                                                    <a href=\"file:///home/merkulov/openfl/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:176</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f249eefaf50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     Building <span style=\"color: #800000\">🡆</span> Object <span style=\"color: #800000\">FrameworkAdapterPlugin</span> from <span style=\"color: #800000\">openfl.plugins.frameworks_adapters.pytorch_adapter</span> Module.                         <a href=\"file:///home/merkulov/openfl/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:172</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f249eefae90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     Settings <span style=\"color: #800000\">🡆</span> <span style=\"font-weight: bold\">{}</span>                                                                                                                    <a href=\"file:///home/merkulov/openfl/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:174</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f249eefae10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     Override <span style=\"color: #800000\">🡆</span> <span style=\"font-weight: bold\">{}</span>                                                                                                                    <a href=\"file:///home/merkulov/openfl/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:176</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f249eefae10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[21:05:54] </span><span style=\"color: #000080\">INFO</span>     Starting experiment!                                                                                                       <a href=\"file:///home/merkulov/openfl/openfl/interface/interactive_api/experiment.py\"><span style=\"color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f\">:155</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f249ee89ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     FL-Plan hash is <span style=\"color: #000080\">ccdb6f6cc888dae61ebf9ac68eb7d3e374eb68422fd3f611d4323c06d6848fe29b200ba31d4a07c189fe1ab044422cf9</span>                 <a href=\"file:///home/merkulov/openfl/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:232</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f249eefad10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     FL-Plan hash is <span style=\"color: #000080\">ccdb6f6cc888dae61ebf9ac68eb7d3e374eb68422fd3f611d4323c06d6848fe29b200ba31d4a07c189fe1ab044422cf9</span>                 <a href=\"file:///home/merkulov/openfl/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:232</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f249eefae90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "build() missing 2 required positional arguments: 'template' and 'settings'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_151142/2383147364.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0mdata_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfed_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mrounds_to_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                     opt_treatment='GLOBAL')\n\u001b[0m",
      "\u001b[0;32m~/openfl/openfl/interface/interactive_api/experiment.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self, model_provider, task_keeper, data_loader, rounds_to_train, delta_updates, opt_treatment)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Starting experiment!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0minitial_tensor_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_initial_tensor_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_provider\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             response = self.federation.dir_client.set_new_experiment(\n",
      "\u001b[0;32m~/openfl/openfl/interface/interactive_api/experiment.py\u001b[0m in \u001b[0;36m_get_initial_tensor_dict\u001b[0;34m(self, model_provider)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_initial_tensor_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_provider\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;34m\"\"\"Extract initial weights from the model.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_runner_stub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_core_task_runner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_provider\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_provider\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         tensor_dict, _ = split_tensor_dict_for_holdouts(\n\u001b[1;32m    231\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/openfl/openfl/federated/plan/plan.py\u001b[0m in \u001b[0;36mget_core_task_runner\u001b[0;34m(self, data_loader, model_provider, task_keeper)\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;31m# We are importing a CoreTaskRunner instance!!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunner_\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunner_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPlan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunner_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: build() missing 2 required positional arguments: 'template' and 'settings'"
     ]
    }
   ],
   "source": [
    "# If I use autoreload I got a pickling error\n",
    "\n",
    "# The following command zips the workspace and python requirements to be transfered to collaborator nodes\n",
    "fl_experiment.start(model_provider=MI, \n",
    "                    task_keeper=TI,\n",
    "                    data_loader=fed_dataset,\n",
    "                    rounds_to_train=3,\n",
    "                    opt_treatment='RESET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc4f89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If user want to stop IPython session, then reconnect and check how experiment is going \n",
    "# fl_experiment.restore_experiment_state(MI)\n",
    "\n",
    "fl_experiment.stream_metrics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
